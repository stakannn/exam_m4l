{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аня Александрова бкл-192\n",
    "вариант 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дан код на языке Python, выравнивание в котором выполнено при помощи пробелов, все операторы записаны в одну строку, классы не используются. \n",
    "Представьте этот код в виде дерева по следующему алгоритму.\n",
    "Корнем дерева является фиктивная вершина. \n",
    "Все строки кода с одинаковым отступом являются вершинами одного уровня. \n",
    "Родителем строки является последняя перед ней строка с уровнем отступа на один меньше, при этом считается не число пробелов, а факт увеличения их количества. \n",
    "Потомки идут в том порядке, в котором они записаны в файле.\n",
    "По заданному имени функции проверьте, является ли данная функция рекурсивной. \n",
    "В общем случае, условные конструкции, циклы и проч. не могут препятствовать вызову функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def to_articles():\n",
      "    os.mkdir('./data/articles')\n",
      "    p = './data/union'\n",
      "    for f in os.listdir(p):\n",
      "        f = p + '/' + f\n",
      "        with open(f) as file:\n",
      "            text = file.read()\n",
      "            for t in text.split('\\n\\n')[:-1]:\n",
      "                id = re.findall('\\{id:(\\d+)}', t)[0]\n",
      "                name = id + '.tsv'\n",
      "                path = '/home/valeria/PycharmProjects/Pogrom/data/articles/' + name\n",
      "                # print(path)\n",
      "                with open(path, 'w') as file_to_write:\n",
      "                    file_to_write.write(t)\n",
      "\n",
      "\n",
      "def to_categories():\n",
      "    path = './data/cats'\n",
      "    os.mkdir(path)\n",
      "    for f in os.listdir('./data/articles'):\n",
      "        name = f\n",
      "        f = './data/articles/' + f\n",
      "        # print(f)\n",
      "        with open(f, 'r') as file:\n",
      "            text = file.readlines()\n",
      "            topics = text[1].rstrip('\\n').rstrip('}').lstrip('{').split('|')\n",
      "            for topic in topics:\n",
      "                topic = topic.split('/')\n",
      "                # print(topic)\n",
      "                # dirlist = os.listdir(path)\n",
      "                path1 = path +'/' + topic[0]\n",
      "                path2 = path1 + '/' + topic[1]\n",
      "                if not topic[0] in os.listdir(path):\n",
      "                    os.mkdir(path1)\n",
      "                if not topic[1] in os.listdir(path1):\n",
      "                    os.mkdir(path2)\n",
      "                final_path = path2 + '/' + name\n",
      "                # print(final_path)\n",
      "                with open(final_path, 'w') as file_to_write:\n",
      "                    file_to_write.write(''.join(text[2:]))\n",
      "\n",
      "\n",
      "def to_nlp():\n",
      "    path = './data/cats/Natural Language Processing'\n",
      "    with open('./data/nlp.txt', 'w') as file_to_write:\n",
      "        for roots, dirs, files in os.walk(path):\n",
      "            # print(roots, files)\n",
      "            for file in files:\n",
      "                filename = roots + '/' + file\n",
      "                # print(filename)\n",
      "                with open(filename, 'r') as f:\n",
      "                    text = f.read()\n",
      "                    lines = text.split('\\n')\n",
      "                    # print(lines[:5])\n",
      "                    for line in lines:\n",
      "                        line = line.split('\\t')\n",
      "                        # print(line)\n",
      "                        if float(line[2]) < 1 and 'РјСѓР¶' in line[3]:\n",
      "                            file_to_write.write(line[0])\n",
      "                            file_to_write.write('\\n')\n",
      "\n",
      "\n",
      "def to_freq():\n",
      "    list_of_names = [str(i*100) + '.union' for i in range(7)]\n",
      "    # print(list_of_names)\n",
      "    path = './data/union/'\n",
      "    for name in list_of_names:\n",
      "        lemm_file = path + name.split('.')[0] + '.dict'\n",
      "        # print(lemm_file)\n",
      "        with open(path+name, 'r') as file:\n",
      "            lines = file.readlines()\n",
      "            lemm_list = []\n",
      "            for line in lines:\n",
      "                # print(line)\n",
      "                if line[0] != '{' and line != '\\n':\n",
      "                    lemm_list.append(line.split('\\t')[1])\n",
      "            cnt = Counter(lemm_list).most_common()\n",
      "            # print(cnt[:10])\n",
      "            with open(lemm_file, 'w') as file_to_write:\n",
      "                for thing in cnt:\n",
      "                    to_write = thing[0] + ',' + str(round(thing[1]/len(lemm_list), 5))\n",
      "                    file_to_write.write(to_write)\n",
      "                    file_to_write.write('\\n')\n"
     ]
    }
   ],
   "source": [
    "with open('se') as filename:\n",
    "    code_lines = filename.read()\n",
    "    print(code_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def to_articles():\n",
      "    os.mkdir('./data/articles')\n",
      "    p = './data/union'\n",
      "    for f in os.listdir(p):\n",
      "        f = p + '/' + f\n",
      "        with open(f) as file:\n",
      "            text = file.read()\n",
      "            for t in text.split('\\n\\n')[:-1]:\n",
      "                id = re.findall('\\{id:(\\d+)}', t)[0]\n",
      "                name = id + '.tsv'\n",
      "                path = '/home/valeria/PycharmProjects/Pogrom/data/articles/' + name\n",
      "                # print(path)\n",
      "                with open(path, 'w') as file_to_write:\n",
      "                    file_to_write.write(t)\n",
      "_____\n",
      "\n",
      "def to_categories():\n",
      "    path = './data/cats'\n",
      "    os.mkdir(path)\n",
      "    for f in os.listdir('./data/articles'):\n",
      "        name = f\n",
      "        f = './data/articles/' + f\n",
      "        # print(f)\n",
      "        with open(f, 'r') as file:\n",
      "            text = file.readlines()\n",
      "            topics = text[1].rstrip('\\n').rstrip('}').lstrip('{').split('|')\n",
      "            for topic in topics:\n",
      "                topic = topic.split('/')\n",
      "                # print(topic)\n",
      "                # dirlist = os.listdir(path)\n",
      "                path1 = path +'/' + topic[0]\n",
      "                path2 = path1 + '/' + topic[1]\n",
      "                if not topic[0] in os.listdir(path):\n",
      "                    os.mkdir(path1)\n",
      "                if not topic[1] in os.listdir(path1):\n",
      "                    os.mkdir(path2)\n",
      "                final_path = path2 + '/' + name\n",
      "                # print(final_path)\n",
      "                with open(final_path, 'w') as file_to_write:\n",
      "                    file_to_write.write(''.join(text[2:]))\n",
      "_____\n",
      "\n",
      "def to_nlp():\n",
      "    path = './data/cats/Natural Language Processing'\n",
      "    with open('./data/nlp.txt', 'w') as file_to_write:\n",
      "        for roots, dirs, files in os.walk(path):\n",
      "            # print(roots, files)\n",
      "            for file in files:\n",
      "                filename = roots + '/' + file\n",
      "                # print(filename)\n",
      "                with open(filename, 'r') as f:\n",
      "                    text = f.read()\n",
      "                    lines = text.split('\\n')\n",
      "                    # print(lines[:5])\n",
      "                    for line in lines:\n",
      "                        line = line.split('\\t')\n",
      "                        # print(line)\n",
      "                        if float(line[2]) < 1 and 'РјСѓР¶' in line[3]:\n",
      "                            file_to_write.write(line[0])\n",
      "                            file_to_write.write('\\n')\n",
      "_____\n",
      "\n",
      "def to_freq():\n",
      "    list_of_names = [str(i*100) + '.union' for i in range(7)]\n",
      "    # print(list_of_names)\n",
      "    path = './data/union/'\n",
      "    for name in list_of_names:\n",
      "        lemm_file = path + name.split('.')[0] + '.dict'\n",
      "        # print(lemm_file)\n",
      "        with open(path+name, 'r') as file:\n",
      "            lines = file.readlines()\n",
      "            lemm_list = []\n",
      "            for line in lines:\n",
      "                # print(line)\n",
      "                if line[0] != '{' and line != '\\n':\n",
      "                    lemm_list.append(line.split('\\t')[1])\n",
      "            cnt = Counter(lemm_list).most_common()\n",
      "            # print(cnt[:10])\n",
      "            with open(lemm_file, 'w') as file_to_write:\n",
      "                for thing in cnt:\n",
      "                    to_write = thing[0] + ',' + str(round(thing[1]/len(lemm_list), 5))\n",
      "                    file_to_write.write(to_write)\n",
      "                    file_to_write.write('\\n')\n",
      "_____\n"
     ]
    }
   ],
   "source": [
    "pieces = code_lines.split('\\n\\n')\n",
    "for piece in pieces:\n",
    "    print(piece)\n",
    "    print('_____')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graphs = []\n",
    "for piece in pieces:\n",
    "    piece = piece.split('\\n')\n",
    "    main_line = []\n",
    "    side_line_1 = []\n",
    "    side_line_2 = []\n",
    "    side_line_3 = []\n",
    "    side_line_4 = []\n",
    "    side_line_5 = []\n",
    "    for line in piece:\n",
    "        if line.startswith('def'):\n",
    "            main_line.append(line)\n",
    "        if not line.startswith('     ') and not line in main_line:\n",
    "            side_line_1.append(line)\n",
    "        if not line.startswith('         ') and not line in main_line and not line in side_line_1:\n",
    "            side_line_2.append(line)\n",
    "        if not line.startswith('             ') and not line in main_line and not line in side_line_1 and not line in side_line_2:\n",
    "            side_line_3.append(line)\n",
    "        if not line.startswith('                 ') and not line in main_line and not line in side_line_1 and not line in side_line_2 and not line in side_line_3:\n",
    "            side_line_4.append(line)\n",
    "        if not line in main_line and not line in side_line_1 and not line in side_line_2 and not line in side_line_3 and not line in side_line_4:\n",
    "            side_line_5.append(line)\n",
    "    list_lists = []\n",
    "    list_lists.append(main_line)\n",
    "    list_lists.append(side_line_1)\n",
    "    list_lists.append(side_line_2)\n",
    "    list_lists.append(side_line_3)\n",
    "    list_lists.append(side_line_4)\n",
    "    list_lists.append(side_line_5)\n",
    "\n",
    "    graphs.append(graph_creator(list_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'def to_articles():': [[\"    os.mkdir('./data/articles')\", \"    p = './data/union'\", '    for f in os.listdir(p):'], {'    for f in os.listdir(p):': [[\"        f = p + '/' + f\", '        with open(f) as file:'], {'        with open(f) as file:': [['            text = file.read()', \"            for t in text.split('\\\\n\\\\n')[:-1]:\"], {\"            for t in text.split('\\\\n\\\\n')[:-1]:\": [[\"                id = re.findall('\\\\{id:(\\\\d+)}', t)[0]\", \"                name = id + '.tsv'\", \"                path = '/home/valeria/PycharmProjects/Pogrom/data/articles/' + name\", '                # print(path)', \"                with open(path, 'w') as file_to_write:\"], {\"                with open(path, 'w') as file_to_write:\": ['                    file_to_write.write(t)']}]}]}]}]}, {'def to_categories():': [['', \"    path = './data/cats'\", '    os.mkdir(path)', \"    for f in os.listdir('./data/articles'):\"], {\"    for f in os.listdir('./data/articles'):\": [['        name = f', \"        f = './data/articles/' + f\", '        # print(f)', \"        with open(f, 'r') as file:\"], {\"        with open(f, 'r') as file:\": [['            text = file.readlines()', \"            topics = text[1].rstrip('\\\\n').rstrip('}').lstrip('{').split('|')\", '            for topic in topics:'], {'            for topic in topics:': [[\"                topic = topic.split('/')\", '                # print(topic)', '                # dirlist = os.listdir(path)', \"                path1 = path +'/' + topic[0]\", \"                path2 = path1 + '/' + topic[1]\", '                if not topic[0] in os.listdir(path):', '                if not topic[1] in os.listdir(path1):', \"                final_path = path2 + '/' + name\", '                # print(final_path)', \"                with open(final_path, 'w') as file_to_write:\"], {\"                with open(final_path, 'w') as file_to_write:\": ['                    os.mkdir(path1)', '                    os.mkdir(path2)', \"                    file_to_write.write(''.join(text[2:]))\"]}]}]}]}]}, {'def to_nlp():': [['', \"    path = './data/cats/Natural Language Processing'\", \"    with open('./data/nlp.txt', 'w') as file_to_write:\"], {\"    with open('./data/nlp.txt', 'w') as file_to_write:\": [['        for roots, dirs, files in os.walk(path):'], {'        for roots, dirs, files in os.walk(path):': [['            # print(roots, files)', '            for file in files:'], {'            for file in files:': [[\"                filename = roots + '/' + file\", '                # print(filename)', \"                with open(filename, 'r') as f:\"], {\"                with open(filename, 'r') as f:\": ['                    text = f.read()', \"                    lines = text.split('\\\\n')\", '                    # print(lines[:5])', '                    for line in lines:', \"                        line = line.split('\\\\t')\", '                        # print(line)', \"                        if float(line[2]) < 1 and 'РјСѓР¶' in line[3]:\", '                            file_to_write.write(line[0])', \"                            file_to_write.write('\\\\n')\"]}]}]}]}]}, {'def to_freq():': [['', \"    list_of_names = [str(i*100) + '.union' for i in range(7)]\", '    # print(list_of_names)', \"    path = './data/union/'\", '    for name in list_of_names:'], {'    for name in list_of_names:': [[\"        lemm_file = path + name.split('.')[0] + '.dict'\", '        # print(lemm_file)', \"        with open(path+name, 'r') as file:\"], {\"        with open(path+name, 'r') as file:\": [['            lines = file.readlines()', '            lemm_list = []', '            for line in lines:', '            cnt = Counter(lemm_list).most_common()', '            # print(cnt[:10])', \"            with open(lemm_file, 'w') as file_to_write:\"], {\"            with open(lemm_file, 'w') as file_to_write:\": [['                # print(line)', \"                if line[0] != '{' and line != '\\\\n':\", '                for thing in cnt:'], {'                for thing in cnt:': [\"                    lemm_list.append(line.split('\\\\t')[1])\", \"                    to_write = thing[0] + ',' + str(round(thing[1]/len(lemm_list), 5))\", '                    file_to_write.write(to_write)', \"                    file_to_write.write('\\\\n')\"]}]}]}]}]}]\n"
     ]
    }
   ],
   "source": [
    "print(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_creator(list_of_lines):\n",
    "    graph = {}\n",
    "    main = (list_of_lines[0])[0]\n",
    "    s1s = list_of_lines[1]\n",
    "    s1s_imp = s1s[-1]\n",
    "    s1s = s1s[:-1]\n",
    "    s2s = list_of_lines[2]\n",
    "    s2s_imp = s2s[-1]\n",
    "    s2s = s2s[:-1]\n",
    "    s3s = list_of_lines[3]\n",
    "    s3s_imp = s3s[-1]\n",
    "    s3s = s3s[:-1]\n",
    "    s4s = list_of_lines[4]\n",
    "    s4s_imp = s4s[-1]\n",
    "    s4s = s4s[:-1]\n",
    "    s5s = list_of_lines[5]\n",
    "    so = {main:[s1s, {s1s_imp:[s2s, {s2s_imp:[s3s, {s3s_imp:[s4s, {s4s_imp:s5s}]}]}]}]}\n",
    "    graph.update(so)\n",
    "    return graph\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'zero': [{'def to_articles():': [[\"    os.mkdir('./data/articles')\",\n",
       "     \"    p = './data/union'\",\n",
       "     '    for f in os.listdir(p):'],\n",
       "    {'    for f in os.listdir(p):': [[\"        f = p + '/' + f\",\n",
       "       '        with open(f) as file:'],\n",
       "      {'        with open(f) as file:': [['            text = file.read()',\n",
       "         \"            for t in text.split('\\\\n\\\\n')[:-1]:\"],\n",
       "        {\"            for t in text.split('\\\\n\\\\n')[:-1]:\": [[\"                id = re.findall('\\\\{id:(\\\\d+)}', t)[0]\",\n",
       "           \"                name = id + '.tsv'\",\n",
       "           \"                path = '/home/valeria/PycharmProjects/Pogrom/data/articles/' + name\",\n",
       "           '                # print(path)',\n",
       "           \"                with open(path, 'w') as file_to_write:\"],\n",
       "          {\"                with open(path, 'w') as file_to_write:\": ['                    file_to_write.write(t)']}]}]}]}]},\n",
       "  {'def to_categories():': [['',\n",
       "     \"    path = './data/cats'\",\n",
       "     '    os.mkdir(path)',\n",
       "     \"    for f in os.listdir('./data/articles'):\"],\n",
       "    {\"    for f in os.listdir('./data/articles'):\": [['        name = f',\n",
       "       \"        f = './data/articles/' + f\",\n",
       "       '        # print(f)',\n",
       "       \"        with open(f, 'r') as file:\"],\n",
       "      {\"        with open(f, 'r') as file:\": [['            text = file.readlines()',\n",
       "         \"            topics = text[1].rstrip('\\\\n').rstrip('}').lstrip('{').split('|')\",\n",
       "         '            for topic in topics:'],\n",
       "        {'            for topic in topics:': [[\"                topic = topic.split('/')\",\n",
       "           '                # print(topic)',\n",
       "           '                # dirlist = os.listdir(path)',\n",
       "           \"                path1 = path +'/' + topic[0]\",\n",
       "           \"                path2 = path1 + '/' + topic[1]\",\n",
       "           '                if not topic[0] in os.listdir(path):',\n",
       "           '                if not topic[1] in os.listdir(path1):',\n",
       "           \"                final_path = path2 + '/' + name\",\n",
       "           '                # print(final_path)',\n",
       "           \"                with open(final_path, 'w') as file_to_write:\"],\n",
       "          {\"                with open(final_path, 'w') as file_to_write:\": ['                    os.mkdir(path1)',\n",
       "            '                    os.mkdir(path2)',\n",
       "            \"                    file_to_write.write(''.join(text[2:]))\"]}]}]}]}]},\n",
       "  {'def to_nlp():': [['',\n",
       "     \"    path = './data/cats/Natural Language Processing'\",\n",
       "     \"    with open('./data/nlp.txt', 'w') as file_to_write:\"],\n",
       "    {\"    with open('./data/nlp.txt', 'w') as file_to_write:\": [['        for roots, dirs, files in os.walk(path):'],\n",
       "      {'        for roots, dirs, files in os.walk(path):': [['            # print(roots, files)',\n",
       "         '            for file in files:'],\n",
       "        {'            for file in files:': [[\"                filename = roots + '/' + file\",\n",
       "           '                # print(filename)',\n",
       "           \"                with open(filename, 'r') as f:\"],\n",
       "          {\"                with open(filename, 'r') as f:\": ['                    text = f.read()',\n",
       "            \"                    lines = text.split('\\\\n')\",\n",
       "            '                    # print(lines[:5])',\n",
       "            '                    for line in lines:',\n",
       "            \"                        line = line.split('\\\\t')\",\n",
       "            '                        # print(line)',\n",
       "            \"                        if float(line[2]) < 1 and 'РјСѓР¶' in line[3]:\",\n",
       "            '                            file_to_write.write(line[0])',\n",
       "            \"                            file_to_write.write('\\\\n')\"]}]}]}]}]},\n",
       "  {'def to_freq():': [['',\n",
       "     \"    list_of_names = [str(i*100) + '.union' for i in range(7)]\",\n",
       "     '    # print(list_of_names)',\n",
       "     \"    path = './data/union/'\",\n",
       "     '    for name in list_of_names:'],\n",
       "    {'    for name in list_of_names:': [[\"        lemm_file = path + name.split('.')[0] + '.dict'\",\n",
       "       '        # print(lemm_file)',\n",
       "       \"        with open(path+name, 'r') as file:\"],\n",
       "      {\"        with open(path+name, 'r') as file:\": [['            lines = file.readlines()',\n",
       "         '            lemm_list = []',\n",
       "         '            for line in lines:',\n",
       "         '            cnt = Counter(lemm_list).most_common()',\n",
       "         '            # print(cnt[:10])',\n",
       "         \"            with open(lemm_file, 'w') as file_to_write:\"],\n",
       "        {\"            with open(lemm_file, 'w') as file_to_write:\": [['                # print(line)',\n",
       "           \"                if line[0] != '{' and line != '\\\\n':\",\n",
       "           '                for thing in cnt:'],\n",
       "          {'                for thing in cnt:': [\"                    lemm_list.append(line.split('\\\\t')[1])\",\n",
       "            \"                    to_write = thing[0] + ',' + str(round(thing[1]/len(lemm_list), 5))\",\n",
       "            '                    file_to_write.write(to_write)',\n",
       "            \"                    file_to_write.write('\\\\n')\"]}]}]}]}]}]}"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def graph_uniter(graphs):\n",
    "    graph = {'zero':graphs}    \n",
    "    return(graph)\n",
    "graph_uniter(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
